{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5e705b",
   "metadata": {
    "papermill": {
     "duration": 0.007229,
     "end_time": "2023-08-26T18:00:33.299120",
     "exception": false,
     "start_time": "2023-08-26T18:00:33.291891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sources\n",
    "- Regressor idea: https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-feature-engineering\n",
    "### Previous notebook:\n",
    "- https://www.kaggle.com/code/josemariasabater/commonlit-roberta-base-with-prompts/edit/run/139550119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b02b81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:00:33.314380Z",
     "iopub.status.busy": "2023-08-26T18:00:33.313459Z",
     "iopub.status.idle": "2023-08-26T18:01:05.565952Z",
     "shell.execute_reply": "2023-08-26T18:01:05.564776Z"
    },
    "papermill": {
     "duration": 32.262658,
     "end_time": "2023-08-26T18:01:05.568516",
     "exception": false,
     "start_time": "2023-08-26T18:00:33.305858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9933f0e",
   "metadata": {
    "papermill": {
     "duration": 0.006932,
     "end_time": "2023-08-26T18:01:05.582682",
     "exception": false,
     "start_time": "2023-08-26T18:01:05.575750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d491e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:05.599088Z",
     "iopub.status.busy": "2023-08-26T18:01:05.598070Z",
     "iopub.status.idle": "2023-08-26T18:01:22.823459Z",
     "shell.execute_reply": "2023-08-26T18:01:22.822559Z"
    },
    "papermill": {
     "duration": 17.236554,
     "end_time": "2023-08-26T18:01:22.826102",
     "exception": false,
     "start_time": "2023-08-26T18:01:05.589548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "import string\n",
    "\n",
    "# %load_ext lab_black\n",
    "\n",
    "# logging settings\n",
    "\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# disable_progress_bar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57416179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:22.841794Z",
     "iopub.status.busy": "2023-08-26T18:01:22.841567Z",
     "iopub.status.idle": "2023-08-26T18:01:22.851432Z",
     "shell.execute_reply": "2023-08-26T18:01:22.850589Z"
    },
    "papermill": {
     "duration": 0.019938,
     "end_time": "2023-08-26T18:01:22.853440",
     "exception": false,
     "start_time": "2023-08-26T18:01:22.833502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f595886",
   "metadata": {
    "papermill": {
     "duration": 0.007035,
     "end_time": "2023-08-26T18:01:22.867477",
     "exception": false,
     "start_time": "2023-08-26T18:01:22.860442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c278078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:22.882416Z",
     "iopub.status.busy": "2023-08-26T18:01:22.882188Z",
     "iopub.status.idle": "2023-08-26T18:01:22.887402Z",
     "shell.execute_reply": "2023-08-26T18:01:22.886203Z"
    },
    "papermill": {
     "duration": 0.014974,
     "end_time": "2023-08-26T18:01:22.889421",
     "exception": false,
     "start_time": "2023-08-26T18:01:22.874447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "    # model_name = \"/kaggle/input/debertav3base\"\n",
    "    model_name = \"debertav3base\"\n",
    "    learning_rate = 1.2e-5\n",
    "    weight_decay = 0.02\n",
    "    hidden_dropout_prob = 0.1\n",
    "    attention_probs_dropout_prob = 0.01\n",
    "    num_train_epochs = 3\n",
    "    n_splits = 4\n",
    "    batch_size = 8\n",
    "    random_seed = 42\n",
    "    save_steps = 100\n",
    "    max_length = 512\n",
    "    use_prompts = False\n",
    "    warmup_ratio = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96226f",
   "metadata": {
    "papermill": {
     "duration": 0.006801,
     "end_time": "2023-08-26T18:01:22.903259",
     "exception": false,
     "start_time": "2023-08-26T18:01:22.896458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ff4cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:22.918531Z",
     "iopub.status.busy": "2023-08-26T18:01:22.918312Z",
     "iopub.status.idle": "2023-08-26T18:01:23.031083Z",
     "shell.execute_reply": "2023-08-26T18:01:23.030219Z"
    },
    "papermill": {
     "duration": 0.122968,
     "end_time": "2023-08-26T18:01:23.033475",
     "exception": false,
     "start_time": "2023-08-26T18:01:22.910507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "# Local\n",
    "\n",
    "#DATA_DIR = \"./data/\"\n",
    "\n",
    "#prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "#prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "#summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "#summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "#sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ca6590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:23.050065Z",
     "iopub.status.busy": "2023-08-26T18:01:23.048731Z",
     "iopub.status.idle": "2023-08-26T18:01:23.077153Z",
     "shell.execute_reply": "2023-08-26T18:01:23.076297Z"
    },
    "papermill": {
     "duration": 0.038441,
     "end_time": "2023-08-26T18:01:23.079085",
     "exception": false,
     "start_time": "2023-08-26T18:01:23.040644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id                                              004e978e639e\n",
       "prompt_id                                                     3b9047\n",
       "text               In Egypt, there were many occupations and soci...\n",
       "content                                                     3.128928\n",
       "wording                                                     4.231226\n",
       "prompt_question    In complete sentences, summarize the structure...\n",
       "prompt_title                               Egyptian Social Structure\n",
       "prompt_text        Egyptian society was structured like a pyramid...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing\n",
    "random_nr = np.random.randint(0, len(prompts_train))\n",
    "merged_train = pd.merge(summaries_train, prompts_train, how=\"left\", on=\"prompt_id\")\n",
    "example1 = merged_train.iloc[random_nr].copy()\n",
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008ecd3",
   "metadata": {
    "papermill": {
     "duration": 0.006926,
     "end_time": "2023-08-26T18:01:23.093594",
     "exception": false,
     "start_time": "2023-08-26T18:01:23.086668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1eb25",
   "metadata": {
    "papermill": {
     "duration": 0.007012,
     "end_time": "2023-08-26T18:01:23.107706",
     "exception": false,
     "start_time": "2023-08-26T18:01:23.100694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ideas\n",
    "Overlaps\n",
    "Quotes\n",
    "Length of Summary vs Length of text\n",
    "Grammar mistakes\n",
    "Repeated vocabulary inside the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b00378b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:01:23.123665Z",
     "iopub.status.busy": "2023-08-26T18:01:23.123465Z",
     "iopub.status.idle": "2023-08-26T18:02:05.736749Z",
     "shell.execute_reply": "2023-08-26T18:02:05.735528Z"
    },
    "papermill": {
     "duration": 42.633826,
     "end_time": "2023-08-26T18:02:05.748717",
     "exception": true,
     "start_time": "2023-08-26T18:01:23.114891",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">417</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 417 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 418 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 419 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 420 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">118</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> check_use_auth_token:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=ha   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>118 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_download.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1291</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hf_hub_download</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1288 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" and downloads online, set 'local_files_only' to False.\"</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1291 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> LocalEntryNotFoundError(                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Connection error, and we cannot find the requested files in\"</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" the disk cache. Please try again or make sure your Internet\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1294 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" connection is on.\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">LocalEntryNotFoundError: </span>Connection error, and we cannot find the requested files in the disk cache. Please try \n",
       "again or make sure your Internet connection is on.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">123</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> merged_df                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>123 Preprocessor = Preprocessor(CFG.model_name)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Preprocessor</span>:                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model_name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer = AutoTokenizer.from_pretrained(model_name)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Spacy NER count</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.spacy_ner_model = spacy.load(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"en_core_web_sm\"</span>,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">658</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If that did not work, let's try to use the config.</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">656 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config_tokenizer_class <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">657 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(config, PretrainedConfig):                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>658 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>config = AutoConfig.from_pretrained(                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">659 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pretrained_model_name_or_path, trust_remote_code=trust_remote_code,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">660 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config_tokenizer_class = config.tokenizer_class                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">944</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_from_auto\"</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">942 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"name_or_path\"</span>] = pretrained_model_name_or_path                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">943 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>trust_remote_code = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"trust_remote_code\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>944 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">945 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>has_remote_code = <span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"AutoConfig\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"aut</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">946 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>has_local_code = <span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> CO   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">947 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>trust_remote_code = resolve_trust_remote_code(                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">574</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config_dict</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">571 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">572 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>original_kwargs = copy.deepcopy(kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">573 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Get config dict associated with the base config file</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>574 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_config_dict(pretrained_model_name_or_path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">576 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>original_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">577 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">629</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load from local folder or from cache or download from model Hub and ca</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>629 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>resolved_config_file = cached_file(                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pretrained_model_name_or_path,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>configuration_file,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>cache_dir=cache_dir,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">452</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 449 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> resolved_file                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 450 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _raise_exceptions_for_missing_entries <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _raise_exceptions_for_connec  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 451 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 452 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"We couldn't connect to '{</span>HUGGINGFACE_CO_RESOLVE_ENDPOINT<span style=\"color: #808000; text-decoration-color: #808000\">}' to load this fi</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 454 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" cached files and it looks like {</span>path_or_repo_id<span style=\"color: #808000; text-decoration-color: #808000\">} is not the path to a dir</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 455 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" {</span>full_filename<span style=\"color: #808000; text-decoration-color: #808000\">}.\\nCheckout your internet connection or see how to run the</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>We couldn't connect to <span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co'</span> to load this file, couldn't find it in the cached files \n",
       "and it looks like debertav3base is not the path to a directory containing a file named config.json.\n",
       "Checkout your internet connection or see how to run the library in offline mode at \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/docs/transformers/installation#offline-mode'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m417\u001b[0m in \u001b[92mcached_file\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 415 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 417 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 418 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 419 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 420 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m118\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m118 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.py\u001b[0m:\u001b[94m1291\u001b[0m in \u001b[92mhf_hub_download\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1288 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m and downloads online, set \u001b[0m\u001b[33m'\u001b[0m\u001b[33mlocal_files_only\u001b[0m\u001b[33m'\u001b[0m\u001b[33m to False.\u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1289 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1290 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1291 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m LocalEntryNotFoundError(                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1292 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mConnection error, and we cannot find the requested files in\u001b[0m\u001b[33m\"\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1293 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m the disk cache. Please try again or make sure your Internet\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1294 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m connection is on.\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mLocalEntryNotFoundError: \u001b[0mConnection error, and we cannot find the requested files in the disk cache. Please try \n",
       "again or make sure your Internet connection is on.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m123\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m merged_df                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m123 Preprocessor = Preprocessor(CFG.model_name)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  1 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mPreprocessor\u001b[0m:                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  2 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, model_name: \u001b[96mstr\u001b[0m) -> \u001b[94mNone\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  3 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.tokenizer = AutoTokenizer.from_pretrained(model_name)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  4 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Spacy NER count\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  5 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.spacy_ner_model = spacy.load(                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  6 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33men_core_web_sm\u001b[0m\u001b[33m\"\u001b[0m,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtokenization_auto.py\u001b[0m:\u001b[94m658\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m655 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If that did not work, let's try to use the config.\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m656 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m config_tokenizer_class \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m657 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(config, PretrainedConfig):                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m658 \u001b[2m│   │   │   │   \u001b[0mconfig = AutoConfig.from_pretrained(                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m659 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path, trust_remote_code=trust_remote_code,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m660 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m661 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig_tokenizer_class = config.tokenizer_class                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mconfiguration_auto.py\u001b[0m:\u001b[94m944\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m941 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_from_auto\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m942 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mname_or_path\u001b[0m\u001b[33m\"\u001b[0m] = pretrained_model_name_or_path                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m943 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtrust_remote_code\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m944 \u001b[2m│   │   \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m945 \u001b[0m\u001b[2m│   │   \u001b[0mhas_remote_code = \u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mAutoConfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33maut\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m946 \u001b[0m\u001b[2m│   │   \u001b[0mhas_local_code = \u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m] \u001b[95min\u001b[0m CO   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m947 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = resolve_trust_remote_code(                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m574\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mget_config_dict\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m572 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m574 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_name_or_path, **kwar   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m576 \u001b[0m\u001b[2m│   │   │   \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m577 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m629\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_get_config_dict\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m626 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m627 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m628 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Load from local folder or from cache or download from model Hub and ca\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m629 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = cached_file(                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m630 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m631 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfiguration_file,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m632 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcache_dir=cache_dir,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m452\u001b[0m in \u001b[92mcached_file\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 449 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m resolved_file                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 450 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _raise_exceptions_for_missing_entries \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m _raise_exceptions_for_connec  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 451 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 452 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 453 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mWe couldn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt connect to \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m to load this fi\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 454 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m cached files and it looks like \u001b[0m\u001b[33m{\u001b[0mpath_or_repo_id\u001b[33m}\u001b[0m\u001b[33m is not the path to a dir\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 455 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m{\u001b[0mfull_filename\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33mCheckout your internet connection or see how to run the\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mWe couldn't connect to \u001b[32m'https://huggingface.co'\u001b[0m to load this file, couldn't find it in the cached files \n",
       "and it looks like debertav3base is not the path to a directory containing a file named config.json.\n",
       "Checkout your internet connection or see how to run the library in offline mode at \n",
       "\u001b[32m'https://huggingface.co/docs/transformers/installation#offline-mode'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, model_name: str) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Spacy NER count\n",
    "        self.spacy_ner_model = spacy.load(\n",
    "            \"en_core_web_sm\",\n",
    "        )\n",
    "        self.speller = SpellChecker()\n",
    "        self.STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def count_text_length(self, df: pd.DataFrame, column: str) -> pd.Series:\n",
    "        return df[column].progress_apply(lambda x: len(self.tokenizer.encode(x)))\n",
    "\n",
    "    def non_stop_word_overlap(self, row: pd.Series) -> float:\n",
    "        \"\"\"intersection(prompt_text, text) after removing stop words\"\"\"\n",
    "\n",
    "        def check_is_stop_word(word):\n",
    "            normalized_word = word.lower().strip(\"▁\")\n",
    "            return (\n",
    "                normalized_word not in self.STOP_WORDS\n",
    "                and normalized_word not in string.punctuation\n",
    "            )\n",
    "\n",
    "        prompt_words = row[\"prompt_tokens\"]\n",
    "        summary_words = row[\"summary_tokens\"]\n",
    "        # Remove stop words\n",
    "        prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "        summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "\n",
    "    def ngrams(self, input_list: list, n: int) -> list[str]:\n",
    "        \"\"\"Returns a list of ngrams\"\"\"\n",
    "        ngrams_ = zip(*[input_list[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams_]\n",
    "\n",
    "    def get_ngram_overlap(self, row: pd.Series, n: int) -> float:\n",
    "        \"\"\"Returns the ngram overlap between prompt and summary\"\"\"\n",
    "        summary_ngrams = self.ngrams(row[\"summary_tokens\"], n)\n",
    "        prompt_ngrams = self.ngrams(row[\"prompt_tokens\"], n)\n",
    "\n",
    "        return len(set(summary_ngrams).intersection(set(prompt_ngrams)))\n",
    "\n",
    "    def get_ner_overlap(self, row: pd.Series) -> float:\n",
    "        \"\"\"Returns the number of overlapping named entities between prompt and summary\"\"\"\n",
    "        prompt_doc = self.spacy_ner_model(row[\"prompt_text\"])\n",
    "        summary_doc = self.spacy_ner_model(row[\"text\"])\n",
    "\n",
    "        prompt_entities = set([ent.text.lower() for ent in prompt_doc.ents])\n",
    "        summary_entities = set([ent.text.lower() for ent in summary_doc.ents])\n",
    "\n",
    "        return len(prompt_entities.intersection(summary_entities))\n",
    "\n",
    "    def get_spelling_error_count(self, row: pd.Series) -> float:\n",
    "        \"\"\"Returns the number of spelling errors in the summary\"\"\"\n",
    "        summary_text = row[\"text\"]\n",
    "        text = \"\".join(char for char in summary_text if char not in string.punctuation)\n",
    "        misspelled = self.speller.unknown(text.split())\n",
    "        return len(misspelled)\n",
    "\n",
    "    def run(self, prompts: pd.DataFrame, summaries: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Tokenize\n",
    "\n",
    "        tqdm.pandas(desc=\"Tokenizing Prompts\")\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].progress_apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Tokenizing Summaries\")\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        merged_df = pd.merge(summaries, prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # Count text length\n",
    "\n",
    "        merged_df[\"prompt_length\"] = self.count_text_length(merged_df, \"prompt_text\")\n",
    "        merged_df[\"summary_length\"] = self.count_text_length(merged_df, \"text\")\n",
    "\n",
    "        # Count non-stop word overlap\n",
    "        tqdm.pandas(desc=\"Counting non-stop word overlap\")\n",
    "        merged_df[\"non_stop_word_overlap\"] = merged_df.progress_apply(\n",
    "            self.non_stop_word_overlap, axis=1\n",
    "        )\n",
    "\n",
    "        # Count ngram overlap\n",
    "        tqdm.pandas(desc=\"Counting unigram overlap\")\n",
    "        merged_df[\"unigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 1), axis=1\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Counting bigram overlap\")\n",
    "        merged_df[\"bigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 2), axis=1\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Counting trigram overlap\")\n",
    "        merged_df[\"trigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 3), axis=1\n",
    "        )\n",
    "\n",
    "        # Count named entity overlap\n",
    "        tqdm.pandas(desc=\"Counting named entity overlap\")\n",
    "        merged_df[\"ner_overlap\"] = merged_df.progress_apply(\n",
    "            self.get_ner_overlap, axis=1\n",
    "        )\n",
    "\n",
    "        # Count spelling errors\n",
    "        tqdm.pandas(desc=\"Counting spelling errors\")\n",
    "        merged_df[\"spelling_error_count\"] = merged_df.progress_apply(\n",
    "            self.get_spelling_error_count, axis=1\n",
    "        )\n",
    "\n",
    "        # Summary/Prompt token length ratio\n",
    "        merged_df[\"token_length_ratio\"] = (\n",
    "            merged_df[\"summary_length\"] / merged_df[\"prompt_length\"]\n",
    "        )\n",
    "        return merged_df\n",
    "\n",
    "\n",
    "Preprocessor = Preprocessor(CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463a386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:52:33.510874Z",
     "iopub.status.busy": "2023-08-25T12:52:33.510585Z",
     "iopub.status.idle": "2023-08-25T13:09:16.755159Z",
     "shell.execute_reply": "2023-08-25T13:09:16.754192Z",
     "shell.execute_reply.started": "2023-08-25T12:52:33.510836Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = Preprocessor.run(prompts_train, summaries_train)\n",
    "test = Preprocessor.run(prompts_test, summaries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cf49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T13:09:17.903602Z",
     "iopub.status.busy": "2023-08-25T13:09:17.903341Z",
     "iopub.status.idle": "2023-08-25T13:09:17.937335Z",
     "shell.execute_reply": "2023-08-25T13:09:17.936508Z",
     "shell.execute_reply.started": "2023-08-25T13:09:17.903568Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae63e13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441aa8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T13:09:17.940126Z",
     "iopub.status.busy": "2023-08-25T13:09:17.939793Z",
     "iopub.status.idle": "2023-08-25T13:09:17.947903Z",
     "shell.execute_reply": "2023-08-25T13:09:17.946896Z",
     "shell.execute_reply.started": "2023-08-25T13:09:17.940093Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred) ** (1 / 2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred) ** (1 / 2)\n",
    "\n",
    "    return (content_score + wording_score) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed60935",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7039866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T14:22:47.308411Z",
     "iopub.status.busy": "2023-08-25T14:22:47.308124Z",
     "iopub.status.idle": "2023-08-25T14:22:47.331873Z",
     "shell.execute_reply": "2023-08-25T14:22:47.330898Z",
     "shell.execute_reply.started": "2023-08-25T14:22:47.308381Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummaryRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        model_dir: str,\n",
    "        target: list[str],\n",
    "        hidden_dropout_prob: float,\n",
    "        attention_probs_dropout_prob: float,\n",
    "        max_length: int,\n",
    "    ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"text\"]\n",
    "        self.input_col = \"input\"\n",
    "\n",
    "        self.target = target\n",
    "        self.target_cols = target\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        #self.model_config = AutoConfig.from_pretrained(model_name)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n",
    "                \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob,\n",
    "                \"num_labels\": 2,\n",
    "                \"problem_type\": \"regression\",\n",
    "            }\n",
    "        )\n",
    "        self.data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "\n",
    "        seed_everything(seed=42)\n",
    "        print(self.target[0])\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[\"content\"], examples[\"wording\"]]\n",
    "        tokenized = self.tokenizer(\n",
    "            examples[self.input_col],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(\n",
    "            examples[self.input_col],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        fold: int,\n",
    "        train_df: pd.DataFrame,\n",
    "        val_df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        num_train_epochs: float,\n",
    "        save_steps: int,\n",
    "    ) -> None:\n",
    "        sep = self.tokenizer.sep_token\n",
    "        train_df[self.input_col] = (\n",
    "            train_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + train_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + train_df[\"text\"]\n",
    "        )\n",
    "        val_df[self.input_col] = (\n",
    "            val_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + val_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + val_df[\"text\"]\n",
    "        )\n",
    "\n",
    "        train_df = train_df[[self.input_col] + self.target_cols]\n",
    "        val_df = val_df[[self.input_col] + self.target_cols]\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "        val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "        train_dataset_tokenized = train_dataset.map(\n",
    "            self.tokenize_function, batched=False\n",
    "        )\n",
    "        val_dataset_tokenized = val_dataset.map(self.tokenize_function, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            f\"/kaggle/input/{self.model_name}\",\n",
    "            config=self.model_config,\n",
    "        )\n",
    "\n",
    "        model_fold_dir = f\"{self.model_dir}/fold_{fold}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=save_steps,\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"rmse\",\n",
    "            greater_is_better=False,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=save_steps,\n",
    "            # disable_tqdm=True,\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset_tokenized,\n",
    "            eval_dataset=val_dataset_tokenized,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        model_content.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        test_df: pd.DataFrame,\n",
    "        fold: int,\n",
    "    ) -> np.array:\n",
    "        sep = self.tokenizer.sep_token\n",
    "        test_df[self.input_col] = (\n",
    "            test_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + test_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + test_df[\"text\"]\n",
    "        )\n",
    "        test_df = test_df[[self.input_col]]\n",
    "        test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
    "        test_dataset_tokenized = test_dataset.map(\n",
    "            self.tokenize_function_test, batched=False\n",
    "        )\n",
    "        model_fold_dir = f\"{self.model_dir}/fold_{fold}\"\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_dir\n",
    "        )\n",
    "        model_content.eval()\n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train=False,\n",
    "            do_predict=True,\n",
    "            per_device_eval_batch_size=4,\n",
    "            dataloader_drop_last=False,\n",
    "            # disable_tqdm=True,\n",
    "        )\n",
    "\n",
    "        infer_trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=test_args,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "\n",
    "        predictions = infer_trainer.predict(test_dataset_tokenized)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434a2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T14:22:48.694123Z",
     "iopub.status.busy": "2023-08-25T14:22:48.693511Z",
     "iopub.status.idle": "2023-08-25T14:22:48.736641Z",
     "shell.execute_reply": "2023-08-25T14:22:48.735676Z",
     "shell.execute_reply.started": "2023-08-25T14:22:48.694088Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folds\n",
    "\n",
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859f945",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844f312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T14:22:49.126746Z",
     "iopub.status.busy": "2023-08-25T14:22:49.126460Z",
     "iopub.status.idle": "2023-08-25T14:22:49.144581Z",
     "shell.execute_reply": "2023-08-25T14:22:49.143700Z",
     "shell.execute_reply.started": "2023-08-25T14:22:49.126712Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_folds(\n",
    "    train_df: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    target: list[str],\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    "    batch_size: int,\n",
    "    learning_rate: float,\n",
    "    weight_decay: float,\n",
    "    num_train_epochs: float,\n",
    "    save_steps: int,\n",
    "    n_splits: int,\n",
    "    save_each_model: bool,\n",
    "):\n",
    "    if os.path.exists(f\"{model_name}\"):\n",
    "        try:\n",
    "            shutil.rmtree(model_name)\n",
    "        except:\n",
    "            pass\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        print(f\"Training fold {fold}\")\n",
    "\n",
    "        train_data = train_df[train_df[\"fold\"] != fold]\n",
    "        val_data = train_df[train_df[\"fold\"] == fold]\n",
    "\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        model.train(\n",
    "            fold=fold,\n",
    "            train_df=train_data,\n",
    "            val_df=val_data,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "\n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target: list[str],\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    ") -> pd.DataFrame:\n",
    "    for fold in range(CFG.n_splits):\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = model_name\n",
    "        val_data = train_df[train_df[\"fold\"] == fold]\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        predictions = model.predict(test_df=val_data, fold=fold)\n",
    "\n",
    "        train_df.loc[val_data.index, \"content_pred\"] = predictions.predictions[:, 0]\n",
    "        train_df.loc[val_data.index, \"wording_pred\"] = predictions.predictions[:, 1]\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target: list[str],\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    ") -> pd.DataFrame:\n",
    "    for fold in range(CFG.n_splits):\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = model_name\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        predictions = model.predict(test_df=test_df, fold=fold)\n",
    "\n",
    "        test_df.loc[:, f\"content_pred_{fold}\"] = predictions.predictions[:, 0]\n",
    "        test_df.loc[:, f\"wording_pred_{fold}\"] = predictions.predictions[:, 1]\n",
    "    \n",
    "    test_df[\"content_pred\"] = test_df[[f\"content_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "    test_df[\"wording_pred\"] = test_df[[f\"wording_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e03f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T14:22:49.415983Z",
     "iopub.status.busy": "2023-08-25T14:22:49.415715Z",
     "iopub.status.idle": "2023-08-25T14:24:49.932212Z",
     "shell.execute_reply": "2023-08-25T14:24:49.929124Z",
     "shell.execute_reply.started": "2023-08-25T14:22:49.415955Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = [\"content\", \"wording\"]\n",
    "train_folds(\n",
    "    train_df=train,\n",
    "    model_name=CFG.model_name,\n",
    "    target=target,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    "    batch_size=CFG.batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    save_steps=CFG.save_steps,\n",
    "    n_splits=CFG.n_splits,\n",
    "    save_each_model=False,\n",
    ")\n",
    "\n",
    "train = validate(\n",
    "    train_df=train,\n",
    "    target=target,\n",
    "    save_each_model=False,\n",
    "    model_name=CFG.model_name,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    ")\n",
    "\n",
    "# print the score\n",
    "print(\n",
    "    f\"Score: {compt_score(train.content, train.content_pred, train.wording, train.wording_pred)}\"\n",
    ")\n",
    "\n",
    "test = predict(\n",
    "    test_df=test,\n",
    "    target=target,\n",
    "    save_each_model=False,\n",
    "    model_name=CFG.model_name,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94127e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-25T12:51:33.957575Z",
     "iopub.status.idle": "2023-08-25T12:51:33.958349Z",
     "shell.execute_reply": "2023-08-25T12:51:33.958120Z",
     "shell.execute_reply.started": "2023-08-25T12:51:33.958095Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849f868",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.770734,
   "end_time": "2023-08-26T18:02:09.012598",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-26T18:00:23.241864",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
