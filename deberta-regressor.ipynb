{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b54e12",
   "metadata": {
    "papermill": {
     "duration": 0.010901,
     "end_time": "2023-09-02T16:35:21.181552",
     "exception": false,
     "start_time": "2023-09-02T16:35:21.170651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sources\n",
    "- Regressor idea: https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-feature-engineering\n",
    "### Previous notebook:\n",
    "- https://www.kaggle.com/code/josemariasabater/commonlit-roberta-base-with-prompts/edit/run/139550119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e63446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:35:21.204357Z",
     "iopub.status.busy": "2023-09-02T16:35:21.203573Z",
     "iopub.status.idle": "2023-09-02T16:35:53.781509Z",
     "shell.execute_reply": "2023-09-02T16:35:53.780315Z"
    },
    "papermill": {
     "duration": 32.592274,
     "end_time": "2023-09-02T16:35:53.783924",
     "exception": false,
     "start_time": "2023-09-02T16:35:21.191650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bc870",
   "metadata": {
    "papermill": {
     "duration": 0.010073,
     "end_time": "2023-09-02T16:35:53.805014",
     "exception": false,
     "start_time": "2023-09-02T16:35:53.794941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e94a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:35:53.827173Z",
     "iopub.status.busy": "2023-09-02T16:35:53.826856Z",
     "iopub.status.idle": "2023-09-02T16:36:10.616131Z",
     "shell.execute_reply": "2023-09-02T16:36:10.615163Z"
    },
    "papermill": {
     "duration": 16.803715,
     "end_time": "2023-09-02T16:36:10.618918",
     "exception": false,
     "start_time": "2023-09-02T16:35:53.815203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "import string\n",
    "import xgboost as xgb\n",
    "# %load_ext lab_black\n",
    "\n",
    "# logging settings\n",
    "\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# disable_progress_bar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eec37b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:10.641989Z",
     "iopub.status.busy": "2023-09-02T16:36:10.641769Z",
     "iopub.status.idle": "2023-09-02T16:36:10.652997Z",
     "shell.execute_reply": "2023-09-02T16:36:10.652039Z"
    },
    "papermill": {
     "duration": 0.02529,
     "end_time": "2023-09-02T16:36:10.655363",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.630073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327f7b5",
   "metadata": {
    "papermill": {
     "duration": 0.01099,
     "end_time": "2023-09-02T16:36:10.676793",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.665803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22db9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:10.699555Z",
     "iopub.status.busy": "2023-09-02T16:36:10.699273Z",
     "iopub.status.idle": "2023-09-02T16:36:10.705023Z",
     "shell.execute_reply": "2023-09-02T16:36:10.704033Z"
    },
    "papermill": {
     "duration": 0.019847,
     "end_time": "2023-09-02T16:36:10.707210",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.687363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "    # model_name = \"/kaggle/input/debertav3base\"\n",
    "    model_name = \"debertav3base\"\n",
    "    learning_rate = 1.2e-5\n",
    "    weight_decay = 0.02\n",
    "    hidden_dropout_prob = 0.1\n",
    "    attention_probs_dropout_prob = 0.01\n",
    "    num_train_epochs = 3\n",
    "    n_splits = 4\n",
    "    batch_size = 8\n",
    "    random_seed = 42\n",
    "    save_steps = 100\n",
    "    max_length = 512\n",
    "    use_prompts = False\n",
    "    warmup_ratio = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc72143",
   "metadata": {
    "papermill": {
     "duration": 0.010233,
     "end_time": "2023-09-02T16:36:10.728015",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.717782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964f938e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:10.750771Z",
     "iopub.status.busy": "2023-09-02T16:36:10.750547Z",
     "iopub.status.idle": "2023-09-02T16:36:10.893686Z",
     "shell.execute_reply": "2023-09-02T16:36:10.892739Z"
    },
    "papermill": {
     "duration": 0.15717,
     "end_time": "2023-09-02T16:36:10.896092",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.738922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "# Local\n",
    "\n",
    "#DATA_DIR = \"./data/\"\n",
    "\n",
    "#prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "#prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "#summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "#summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "#sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721dc3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:10.920323Z",
     "iopub.status.busy": "2023-09-02T16:36:10.918838Z",
     "iopub.status.idle": "2023-09-02T16:36:10.946012Z",
     "shell.execute_reply": "2023-09-02T16:36:10.945000Z"
    },
    "papermill": {
     "duration": 0.040812,
     "end_time": "2023-09-02T16:36:10.948384",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.907572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id                                              004e978e639e\n",
       "prompt_id                                                     3b9047\n",
       "text               In Egypt, there were many occupations and soci...\n",
       "content                                                     3.128928\n",
       "wording                                                     4.231226\n",
       "prompt_question    In complete sentences, summarize the structure...\n",
       "prompt_title                               Egyptian Social Structure\n",
       "prompt_text        Egyptian society was structured like a pyramid...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing\n",
    "random_nr = np.random.randint(0, len(prompts_train))\n",
    "merged_train = pd.merge(summaries_train, prompts_train, how=\"left\", on=\"prompt_id\")\n",
    "example1 = merged_train.iloc[random_nr].copy()\n",
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8223362",
   "metadata": {
    "papermill": {
     "duration": 0.010557,
     "end_time": "2023-09-02T16:36:10.970177",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.959620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f98d7",
   "metadata": {
    "papermill": {
     "duration": 0.010406,
     "end_time": "2023-09-02T16:36:10.991191",
     "exception": false,
     "start_time": "2023-09-02T16:36:10.980785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ideas\n",
    "Overlaps\n",
    "Quotes\n",
    "Length of Summary vs Length of text\n",
    "Grammar mistakes\n",
    "Repeated vocabulary inside the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef99434b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:11.014735Z",
     "iopub.status.busy": "2023-09-02T16:36:11.014487Z",
     "iopub.status.idle": "2023-09-02T16:36:13.750768Z",
     "shell.execute_reply": "2023-09-02T16:36:13.749818Z"
    },
    "papermill": {
     "duration": 2.751401,
     "end_time": "2023-09-02T16:36:13.753257",
     "exception": false,
     "start_time": "2023-09-02T16:36:11.001856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, model_name: str) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        # Spacy NER count\n",
    "        self.spacy_ner_model = spacy.load(\n",
    "            \"en_core_web_sm\",\n",
    "        )\n",
    "        self.speller = SpellChecker()\n",
    "        self.STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "        self.vectorizer = CountVectorizer\n",
    "\n",
    "    def count_text_length(self, df: pd.DataFrame, column: str) -> pd.Series:\n",
    "        return df[column].progress_apply(lambda x: len(self.tokenizer.encode(x)))\n",
    "\n",
    "    def non_stop_word_overlap(self, row: pd.Series) -> float:\n",
    "        \"\"\"intersection(prompt_text, text) after removing stop words\"\"\"\n",
    "\n",
    "        def check_is_stop_word(word):\n",
    "            normalized_word = word.lower().strip(\"▁\")\n",
    "            return (\n",
    "                normalized_word not in self.STOP_WORDS\n",
    "                and normalized_word not in string.punctuation\n",
    "            )\n",
    "\n",
    "        prompt_words = row[\"prompt_tokens\"]\n",
    "        summary_words = row[\"summary_tokens\"]\n",
    "        # Remove stop words\n",
    "        prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "        summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "\n",
    "    def ngrams(self, input_list: list, n: int) -> list[str]:\n",
    "        \"\"\"Returns a list of ngrams\"\"\"\n",
    "        ngrams_ = zip(*[input_list[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams_]\n",
    "\n",
    "    def get_ngram_overlap(self, row: pd.Series, n: int) -> float:\n",
    "        \"\"\"Returns the ngram overlap between prompt and summary\"\"\"\n",
    "        summary_ngrams = self.ngrams(row[\"summary_tokens\"], n)\n",
    "        prompt_ngrams = self.ngrams(row[\"prompt_tokens\"], n)\n",
    "\n",
    "        return len(set(summary_ngrams).intersection(set(prompt_ngrams)))\n",
    "\n",
    "    def get_ner_overlap(self, row: pd.Series) -> float:\n",
    "        \"\"\"Returns the number of overlapping named entities between prompt and summary\"\"\"\n",
    "        prompt_doc = self.spacy_ner_model(row[\"prompt_text\"])\n",
    "        summary_doc = self.spacy_ner_model(row[\"text\"])\n",
    "\n",
    "        prompt_entities = set([ent.text.lower() for ent in prompt_doc.ents])\n",
    "        summary_entities = set([ent.text.lower() for ent in summary_doc.ents])\n",
    "\n",
    "        return len(prompt_entities.intersection(summary_entities))\n",
    "\n",
    "    def get_spelling_error_count(self, row: pd.Series) -> float:\n",
    "        \"\"\"Returns the number of spelling errors in the summary\"\"\"\n",
    "        summary_text = row[\"text\"]\n",
    "        text = \"\".join(char for char in summary_text if char not in string.punctuation)\n",
    "        misspelled = self.speller.unknown(text.split())\n",
    "        return len(misspelled)\n",
    "    \n",
    "    def get_cosine_similarity(self, row: pd.Series) -> float:\n",
    "        summary_text = row[\"text\"]\n",
    "        prompt_text = row[\"prompt_text\"]\n",
    "        all_text = [summary_text, prompt_text]\n",
    "        self.vectorizer.fit(all_text)\n",
    "\n",
    "        vec1 = self.vectorizer.transform([summary_text]).toarray()\n",
    "        vec2 = self.vectorizer.transform([prompt_text]).toarray()\n",
    "        return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "    def run(self, prompts: pd.DataFrame, summaries: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Tokenize\n",
    "\n",
    "        tqdm.pandas(desc=\"Tokenizing Prompts\")\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].progress_apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Tokenizing Summaries\")\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.tokenizer.convert_ids_to_tokens(\n",
    "                self.tokenizer.encode(x), skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        merged_df = pd.merge(summaries, prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # Count text length\n",
    "\n",
    "        merged_df[\"prompt_length\"] = self.count_text_length(merged_df, \"prompt_text\")\n",
    "        merged_df[\"summary_length\"] = self.count_text_length(merged_df, \"text\")\n",
    "\n",
    "        # Count non-stop word overlap\n",
    "        tqdm.pandas(desc=\"Counting non-stop word overlap\")\n",
    "        merged_df[\"non_stop_word_overlap\"] = merged_df.progress_apply(\n",
    "            self.non_stop_word_overlap, axis=1\n",
    "        )\n",
    "\n",
    "        # Count ngram overlap\n",
    "        tqdm.pandas(desc=\"Counting unigram overlap\")\n",
    "        merged_df[\"unigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 1), axis=1\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Counting bigram overlap\")\n",
    "        merged_df[\"bigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 2), axis=1\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Counting trigram overlap\")\n",
    "        merged_df[\"trigram_overlap\"] = merged_df.progress_apply(\n",
    "            lambda x: self.get_ngram_overlap(x, 3), axis=1\n",
    "        )\n",
    "\n",
    "        # Count named entity overlap\n",
    "        tqdm.pandas(desc=\"Counting named entity overlap\")\n",
    "        merged_df[\"ner_overlap\"] = merged_df.progress_apply(\n",
    "            self.get_ner_overlap, axis=1\n",
    "        )\n",
    "\n",
    "        # Count spelling errors\n",
    "        tqdm.pandas(desc=\"Counting spelling errors\")\n",
    "        merged_df[\"spelling_error_count\"] = merged_df.progress_apply(\n",
    "            self.get_spelling_error_count, axis=1\n",
    "        )\n",
    "\n",
    "        # Summary/Prompt token length ratio\n",
    "        merged_df[\"token_length_ratio\"] = (\n",
    "            merged_df[\"summary_length\"] / merged_df[\"prompt_length\"]\n",
    "        )\n",
    "        tqdm.pandas(desc=\"Calculating cosine similarity\")\n",
    "        merged_df[\"cosine_similarity\"] = merged_df.progress_apply(\n",
    "        self.get_cosine_similarity, axis=1)\n",
    "        \n",
    "        return merged_df\n",
    "    \n",
    "\n",
    "Preprocessor = Preprocessor(CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79fba9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T16:36:13.776271Z",
     "iopub.status.busy": "2023-09-02T16:36:13.776041Z",
     "iopub.status.idle": "2023-09-02T16:53:53.614460Z",
     "shell.execute_reply": "2023-09-02T16:53:53.613234Z"
    },
    "papermill": {
     "duration": 1059.852782,
     "end_time": "2023-09-02T16:53:53.617046",
     "exception": true,
     "start_time": "2023-09-02T16:36:13.764264",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Prompts: 100%|██████████| 4/4 [00:00<00:00, 59.21it/s]\n",
      "Tokenizing Summaries: 100%|██████████| 7165/7165 [00:12<00:00, 577.13it/s]\n",
      "Tokenizing Summaries: 100%|██████████| 7165/7165 [00:16<00:00, 441.12it/s]\n",
      "Tokenizing Summaries: 100%|██████████| 7165/7165 [00:02<00:00, 3485.48it/s]\n",
      "Counting non-stop word overlap: 100%|██████████| 7165/7165 [00:04<00:00, 1641.89it/s]\n",
      "Counting unigram overlap: 100%|██████████| 7165/7165 [00:01<00:00, 5921.58it/s]\n",
      "Counting bigram overlap: 100%|██████████| 7165/7165 [00:02<00:00, 3207.48it/s]\n",
      "Counting trigram overlap: 100%|██████████| 7165/7165 [00:02<00:00, 2810.89it/s]\n",
      "Counting named entity overlap: 100%|██████████| 7165/7165 [16:52<00:00,  7.07it/s]\n",
      "Counting spelling errors: 100%|██████████| 7165/7165 [00:02<00:00, 3496.47it/s]\n",
      "Calculating cosine similarity:   0%|          | 1/7165 [00:00<00:40, 178.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train = Preprocessor.run(prompts_train, summaries_train)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>test = Preprocessor.run(prompts_test, summaries_test)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">132</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>merged_df[<span style=\"color: #808000; text-decoration-color: #808000\">\"summary_length\"</span>] / merged_df[<span style=\"color: #808000; text-decoration-color: #808000\">\"prompt_length\"</span>]                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tqdm.pandas(desc=<span style=\"color: #808000; text-decoration-color: #808000\">\"Calculating cosine similarity\"</span>)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>132 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>merged_df[<span style=\"color: #808000; text-decoration-color: #808000\">\"cosine_similarity\"</span>] = merged_df.progress_apply(                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_cosine_similarity, axis=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> merged_df                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">805</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 802 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Apply the provided function (in **kwargs)</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 803 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># on the df using our wrapper (which provides bar updating)</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 804 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 805 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(df, df_function)(wrapper, **kwargs)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 806 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 807 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>t.close()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 808 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9568</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9565 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs=kwargs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9568 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> op.apply().__finalize__(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, method=<span style=\"color: #808000; text-decoration-color: #808000\">\"apply\"</span>)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9569 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9570 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">applymap</span>(                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9571 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func: PythonFuncType, na_action: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span> | <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, **kwargs               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">apply.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">764</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 761 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.raw:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.apply_raw()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 763 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 764 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.apply_standard()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 765 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 766 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">agg</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>obj = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.obj                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">apply.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">891</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_standard</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 888 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> result                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 889 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 890 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_standard</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 891 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>results, res_index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.apply_series_generator()                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 892 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 893 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># wrap results</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 894 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wrap_results(results, res_index)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">apply.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">907</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_series_generator</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> option_context(<span style=\"color: #808000; text-decoration-color: #808000\">\"mode.chained_assignment\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 905 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(series_gen):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 906 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ignore SettingWithCopy here in case the user mutates</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 907 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>results[i] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.f(v)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 908 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(results[i], ABCSeries):                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 909 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we have a view on v, we need to make a copy because</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 910 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#  series_generator will swap out the underlying data</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">800</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 797 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># on the first column/row to decide whether it can</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># take a fast or slow code path; so stop when t.total==t.n</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>t.update(n=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> t.total <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.n &lt; t.total <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 800 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 801 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 802 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Apply the provided function (in **kwargs)</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 803 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># on the df using our wrapper (which provides bar updating)</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_cosine_similarity</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">66</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>summary_text = row[<span style=\"color: #808000; text-decoration-color: #808000\">\"text\"</span>]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>prompt_text = row[<span style=\"color: #808000; text-decoration-color: #808000\">\"prompt_text\"</span>]                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>all_text = [summary_text, prompt_text]                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 66 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vectorizer.fit(all_text)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vec1 = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vectorizer.transform([summary_text]).toarray()                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vec2 = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vectorizer.transform([prompt_text]).toarray()                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CountVectorizer.fit</span><span style=\"font-weight: bold\">()</span> missing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> required positional argument: <span style=\"color: #008000; text-decoration-color: #008000\">'raw_documents'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train = Preprocessor.run(prompts_train, summaries_train)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mtest = Preprocessor.run(prompts_test, summaries_test)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mrun\u001b[0m:\u001b[94m132\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   │   \u001b[0mmerged_df[\u001b[33m\"\u001b[0m\u001b[33msummary_length\u001b[0m\u001b[33m\"\u001b[0m] / merged_df[\u001b[33m\"\u001b[0m\u001b[33mprompt_length\u001b[0m\u001b[33m\"\u001b[0m]                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0mtqdm.pandas(desc=\u001b[33m\"\u001b[0m\u001b[33mCalculating cosine similarity\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m132 \u001b[2m│   │   \u001b[0mmerged_df[\u001b[33m\"\u001b[0m\u001b[33mcosine_similarity\u001b[0m\u001b[33m\"\u001b[0m] = merged_df.progress_apply(                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.get_cosine_similarity, axis=\u001b[94m1\u001b[0m)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m merged_df                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/tqdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m805\u001b[0m in \u001b[92minner\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 802 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Apply the provided function (in **kwargs)\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 803 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# on the df using our wrapper (which provides bar updating)\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 804 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 805 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mgetattr\u001b[0m(df, df_function)(wrapper, **kwargs)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 806 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 807 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mt.close()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 808 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m9568\u001b[0m in \u001b[92mapply\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9565 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9566 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs=kwargs,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9567 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9568 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m op.apply().__finalize__(\u001b[96mself\u001b[0m, method=\u001b[33m\"\u001b[0m\u001b[33mapply\u001b[0m\u001b[33m\"\u001b[0m)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9569 \u001b[0m\u001b[2m│   \u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9570 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mapplymap\u001b[0m(                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9571 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, func: PythonFuncType, na_action: \u001b[96mstr\u001b[0m | \u001b[94mNone\u001b[0m = \u001b[94mNone\u001b[0m, **kwargs               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mapply.py\u001b[0m:\u001b[94m764\u001b[0m in \u001b[92mapply\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 761 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.raw:                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 762 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.apply_raw()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 763 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 764 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.apply_standard()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 765 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 766 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92magg\u001b[0m(\u001b[96mself\u001b[0m):                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 767 \u001b[0m\u001b[2m│   │   \u001b[0mobj = \u001b[96mself\u001b[0m.obj                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mapply.py\u001b[0m:\u001b[94m891\u001b[0m in \u001b[92mapply_standard\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 888 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m result                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 889 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 890 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mapply_standard\u001b[0m(\u001b[96mself\u001b[0m):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 891 \u001b[2m│   │   \u001b[0mresults, res_index = \u001b[96mself\u001b[0m.apply_series_generator()                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 892 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 893 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# wrap results\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 894 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.wrap_results(results, res_index)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mapply.py\u001b[0m:\u001b[94m907\u001b[0m in \u001b[92mapply_series_generator\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 904 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m option_context(\u001b[33m\"\u001b[0m\u001b[33mmode.chained_assignment\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m):                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 905 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m i, v \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(series_gen):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 906 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# ignore SettingWithCopy here in case the user mutates\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 907 \u001b[2m│   │   │   │   \u001b[0mresults[i] = \u001b[96mself\u001b[0m.f(v)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 908 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(results[i], ABCSeries):                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 909 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# If we have a view on v, we need to make a copy because\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 910 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m#  series_generator will swap out the underlying data\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/tqdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m800\u001b[0m in \u001b[92mwrapper\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 797 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# on the first column/row to decide whether it can\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mt.update(n=\u001b[94m1\u001b[0m \u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m t.total \u001b[95mor\u001b[0m t.n < t.total \u001b[94melse\u001b[0m \u001b[94m0\u001b[0m)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 800 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 801 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 802 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Apply the provided function (in **kwargs)\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 803 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# on the df using our wrapper (which provides bar updating)\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mget_cosine_similarity\u001b[0m:\u001b[94m66\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   \u001b[0msummary_text = row[\u001b[33m\"\u001b[0m\u001b[33mtext\u001b[0m\u001b[33m\"\u001b[0m]                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   \u001b[0mprompt_text = row[\u001b[33m\"\u001b[0m\u001b[33mprompt_text\u001b[0m\u001b[33m\"\u001b[0m]                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0mall_text = [summary_text, prompt_text]                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 66 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.vectorizer.fit(all_text)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2m│   │   \u001b[0mvec1 = \u001b[96mself\u001b[0m.vectorizer.transform([summary_text]).toarray()                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0mvec2 = \u001b[96mself\u001b[0m.vectorizer.transform([prompt_text]).toarray()                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mCountVectorizer.fit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \u001b[32m'raw_documents'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = Preprocessor.run(prompts_train, summaries_train)\n",
    "test = Preprocessor.run(prompts_test, summaries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c255a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:22:17.178684Z",
     "iopub.status.busy": "2023-08-26T18:22:17.178349Z",
     "iopub.status.idle": "2023-08-26T18:22:17.212261Z",
     "shell.execute_reply": "2023-08-26T18:22:17.211304Z",
     "shell.execute_reply.started": "2023-08-26T18:22:17.178654Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc292ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beedee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:22:17.216433Z",
     "iopub.status.busy": "2023-08-26T18:22:17.216239Z",
     "iopub.status.idle": "2023-08-26T18:22:17.223795Z",
     "shell.execute_reply": "2023-08-26T18:22:17.222679Z",
     "shell.execute_reply.started": "2023-08-26T18:22:17.216408Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred) ** (1 / 2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred) ** (1 / 2)\n",
    "\n",
    "    return (content_score + wording_score) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbda0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c6dbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:22:17.225754Z",
     "iopub.status.busy": "2023-08-26T18:22:17.225510Z",
     "iopub.status.idle": "2023-08-26T18:22:17.250681Z",
     "shell.execute_reply": "2023-08-26T18:22:17.249785Z",
     "shell.execute_reply.started": "2023-08-26T18:22:17.225721Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummaryRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        model_dir: str,\n",
    "        target: list[str],\n",
    "        hidden_dropout_prob: float,\n",
    "        attention_probs_dropout_prob: float,\n",
    "        max_length: int,\n",
    "    ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"text\"]\n",
    "        self.input_col = \"input\"\n",
    "\n",
    "        self.target = target\n",
    "        self.target_cols = target\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        #self.model_config = AutoConfig.from_pretrained(model_name)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n",
    "                \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob,\n",
    "                \"num_labels\": 2,\n",
    "                \"problem_type\": \"regression\",\n",
    "            }\n",
    "        )\n",
    "        self.data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "\n",
    "        seed_everything(seed=42)\n",
    "        print(self.target[0])\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[\"content\"], examples[\"wording\"]]\n",
    "        tokenized = self.tokenizer(\n",
    "            examples[self.input_col],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(\n",
    "            examples[self.input_col],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        return tokenized\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        fold: int,\n",
    "        train_df: pd.DataFrame,\n",
    "        val_df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        num_train_epochs: float,\n",
    "        save_steps: int,\n",
    "    ) -> None:\n",
    "        sep = self.tokenizer.sep_token\n",
    "        train_df[self.input_col] = (\n",
    "            train_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + train_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + train_df[\"text\"]\n",
    "        )\n",
    "        val_df[self.input_col] = (\n",
    "            val_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + val_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + val_df[\"text\"]\n",
    "        )\n",
    "\n",
    "        train_df = train_df[[self.input_col] + self.target_cols]\n",
    "        val_df = val_df[[self.input_col] + self.target_cols]\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "        val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "        train_dataset_tokenized = train_dataset.map(\n",
    "            self.tokenize_function, batched=False\n",
    "        )\n",
    "        val_dataset_tokenized = val_dataset.map(self.tokenize_function, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            f\"/kaggle/input/{self.model_name}\",\n",
    "            config=self.model_config,\n",
    "        )\n",
    "\n",
    "        model_fold_dir = f\"{self.model_dir}/fold_{fold}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=save_steps,\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"rmse\",\n",
    "            greater_is_better=False,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=save_steps,\n",
    "            # disable_tqdm=True,\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset_tokenized,\n",
    "            eval_dataset=val_dataset_tokenized,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        model_content.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        test_df: pd.DataFrame,\n",
    "        fold: int,\n",
    "    ) -> np.array:\n",
    "        sep = self.tokenizer.sep_token\n",
    "        test_df[self.input_col] = (\n",
    "            test_df[\"prompt_title\"]\n",
    "            + sep\n",
    "            + test_df[\"prompt_question\"]\n",
    "            + sep\n",
    "            + test_df[\"text\"]\n",
    "        )\n",
    "        test_df = test_df[[self.input_col]]\n",
    "        test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
    "        test_dataset_tokenized = test_dataset.map(\n",
    "            self.tokenize_function_test, batched=False\n",
    "        )\n",
    "        model_fold_dir = f\"{self.model_dir}/fold_{fold}\"\n",
    "        model_dir = f\"{self.model_name}/fold_{fold}\"\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_dir\n",
    "        )\n",
    "        model_content.eval()\n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train=False,\n",
    "            do_predict=True,\n",
    "            per_device_eval_batch_size=4,\n",
    "            dataloader_drop_last=False,\n",
    "            # disable_tqdm=True,\n",
    "        )\n",
    "\n",
    "        infer_trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=test_args,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "\n",
    "        predictions = infer_trainer.predict(test_dataset_tokenized)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35b087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:22:17.252369Z",
     "iopub.status.busy": "2023-08-26T18:22:17.252127Z",
     "iopub.status.idle": "2023-08-26T18:22:17.308248Z",
     "shell.execute_reply": "2023-08-26T18:22:17.307451Z",
     "shell.execute_reply.started": "2023-08-26T18:22:17.252337Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create folds\n",
    "\n",
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315b8a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546b5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T20:59:34.832199Z",
     "iopub.status.busy": "2023-08-26T20:59:34.831834Z",
     "iopub.status.idle": "2023-08-26T20:59:34.896768Z",
     "shell.execute_reply": "2023-08-26T20:59:34.894256Z",
     "shell.execute_reply.started": "2023-08-26T20:59:34.832163Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_folds(\n",
    "    train_df: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    target: list[str],\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    "    batch_size: int,\n",
    "    learning_rate: float,\n",
    "    weight_decay: float,\n",
    "    num_train_epochs: float,\n",
    "    save_steps: int,\n",
    "    n_splits: int,\n",
    "    save_each_model: bool,\n",
    "):\n",
    "    if os.path.exists(f\"{model_name}\"):\n",
    "        try:\n",
    "            shutil.rmtree(model_name)\n",
    "        except:\n",
    "            pass\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        print(f\"Training fold {fold}\")\n",
    "\n",
    "        train_data = train_df[train_df[\"fold\"] != fold]\n",
    "        val_data = train_df[train_df[\"fold\"] == fold]\n",
    "\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        model.train(\n",
    "            fold=fold,\n",
    "            train_df=train_data,\n",
    "            val_df=val_data,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "\n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target: list[str],\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    ") -> pd.DataFrame:\n",
    "    for fold in range(CFG.n_splits):\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        val_data = train_df[train_df[\"fold\"] == fold]\n",
    "        print(\"model name:\", model_name)\n",
    "        print(\"model dir\", model_dir)\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        predictions = model.predict(test_df=val_data, fold=fold)\n",
    "\n",
    "        train_df.loc[val_data.index, \"content_pred\"] = predictions.predictions[:, 0]\n",
    "        train_df.loc[val_data.index, \"wording_pred\"] = predictions.predictions[:, 1]\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target: list[str],\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int,\n",
    ") -> pd.DataFrame:\n",
    "    for fold in range(CFG.n_splits):\n",
    "        if save_each_model:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "        model = SummaryRegressor(\n",
    "            model_name=model_name,\n",
    "            model_dir=model_dir,\n",
    "            target=target,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        predictions = model.predict(test_df=test_df, fold=fold)\n",
    "\n",
    "        test_df.loc[:, f\"content_pred_{fold}\"] = predictions.predictions[:, 0]\n",
    "        test_df.loc[:, f\"wording_pred_{fold}\"] = predictions.predictions[:, 1]\n",
    "    \n",
    "    test_df[\"content_pred\"] = test_df[[f\"content_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "    test_df[\"wording_pred\"] = test_df[[f\"wording_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13aa082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T18:30:03.608446Z",
     "iopub.status.busy": "2023-08-26T18:30:03.608161Z",
     "iopub.status.idle": "2023-08-26T19:44:06.889930Z",
     "shell.execute_reply": "2023-08-26T19:44:06.888530Z",
     "shell.execute_reply.started": "2023-08-26T18:30:03.608404Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = [\"content\", \"wording\"]\n",
    "train_folds(\n",
    "    train_df=train,\n",
    "    model_name=CFG.model_name,\n",
    "    target=target,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    "    batch_size=CFG.batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    save_steps=CFG.save_steps,\n",
    "    n_splits=CFG.n_splits,\n",
    "    save_each_model=False,\n",
    ")\n",
    "\n",
    "train = validate(\n",
    "    train_df=train,\n",
    "    target=target,\n",
    "    save_each_model=False,\n",
    "    model_name=CFG.model_name,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    ")\n",
    "\n",
    "# print the score\n",
    "print(\n",
    "    f\"Score: {compt_score(train.content, train.content_pred, train.wording, train.wording_pred)}\"\n",
    ")\n",
    "\n",
    "test = predict(\n",
    "    test_df=test,\n",
    "    target=target,\n",
    "    save_each_model=False,\n",
    "    model_name=CFG.model_name,\n",
    "    hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "    attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "    max_length=CFG.max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c337520",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-26T18:29:34.170174Z",
     "iopub.status.idle": "2023-08-26T18:29:34.170604Z",
     "shell.execute_reply": "2023-08-26T18:29:34.170401Z",
     "shell.execute_reply.started": "2023-08-26T18:29:34.170380Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b8d33",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"df_after_llm.csvv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01058b3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66881b3c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-26T18:29:34.172468Z",
     "iopub.status.idle": "2023-08-26T18:29:34.172821Z",
     "shell.execute_reply": "2023-08-26T18:29:34.172644Z",
     "shell.execute_reply.started": "2023-08-26T18:29:34.172626Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = [\"content\", \"wording\"]\n",
    "\n",
    "features = [\"content_pred\",\n",
    "            \"wording_pred\",\n",
    "            \"token_length_ratio\",\n",
    "            \"non_stop_word_overlap\",\n",
    "            \"unigram_overlap\",\n",
    "            \"bigram_overlap\", \n",
    "            \"trigram_overlap\",\n",
    "            \"ner_overlap\",\n",
    "            \"spelling_error_count\",\n",
    "            \"summary_length\",\n",
    "            \"cosine_similarity\"]\n",
    "models_dict = {t: [] for t in target}\n",
    "for t in target:\n",
    "    for fold in range(CFG.n_splits):\n",
    "        X_train = train[train[\"fold\"] != fold][features]\n",
    "        Y_train = train[train[\"fold\"] != fold][t]\n",
    "        X_val = train[train[\"fold\"] == fold][features]\n",
    "        Y_val = train[train[\"fold\"] == fold][t]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=Y_val)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"booster\": \"gbtree\"\n",
    "        }\n",
    "        evaluation_results = {}\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "            verbose_eval=100,\n",
    "            early_stopping_rounds=100,\n",
    "            evals_result=evaluation_results,\n",
    "        )\n",
    "        models_dict[t].append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004e22c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd3de5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for t, models in models_dict.items():\n",
    "    for fold, model in enumerate(models):\n",
    "        feature_importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        # Sorting by importance\n",
    "        sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        features_, importances = zip(*sorted_features)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(features_, importances)\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.title(f'Feature Importances for target {t} - Fold {fold + 1}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea0c24",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-26T18:29:34.389287Z",
     "iopub.status.idle": "2023-08-26T18:29:34.389694Z",
     "shell.execute_reply": "2023-08-26T18:29:34.389491Z",
     "shell.execute_reply.started": "2023-08-26T18:29:34.389468Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## CV Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e290375",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmses = []\n",
    "\n",
    "for t in target:\n",
    "    models = models_dict[t]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = train[train[\"fold\"] == fold][features]\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][t]\n",
    "        dmatrix_eval_cv = xgb.DMatrix(X_eval_cv)\n",
    "        pred = model.predict(dmatrix_eval_cv)\n",
    "\n",
    "        trues.extend(y_eval_cv)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131962d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "for t in target:\n",
    "    models = models_dict[t]\n",
    "    preds = []\n",
    "\n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = test[features]\n",
    "        dmatrix_eval_cv = xgb.DMatrix(X_eval_cv)\n",
    "        pred = model.predict(dmatrix_eval_cv)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    pred_dict[t] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41731a9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in target:\n",
    "    preds = pred_dict[t]\n",
    "    for i, pred in enumerate(preds):\n",
    "        test[f\"{t}_pred_{i}\"] = pred\n",
    "\n",
    "    test[t] = test[[f\"{t}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cd8fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1126.369444,
   "end_time": "2023-09-02T16:53:57.724912",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-02T16:35:11.355468",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
